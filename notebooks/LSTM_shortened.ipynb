{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm_model import build_open_loop_lstm, load_open_loop_lstm\n",
    "from data_processing import create_training_split, df_training_split, create_df_3d, create_window_closed_loop, add_new_pred, compute_lyapunov_time_arr, train_valid_test_split, df_train_valid_test_split\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tensorflow_datasets as tfds\n",
    "import plots\n",
    "import importlib\n",
    "plt.rcParams['figure.facecolor'] = 'w'\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm -rf ./50_window_100LSTM/Images/LSTM_0_washout/run_1502/logs/fit/250_oloop/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf = np.genfromtxt('CSV/lorenz_normalized.csv', delimiter=',')\n",
    "time = mydf[0, :]\n",
    "mydf = mydf[1:, :]\n",
    "df_train, df_valid, df_test = df_train_valid_test_split(mydf)\n",
    "time_train, time_valid, time_test = train_valid_test_split(time)\n",
    "x_train, x_valid, x_test = train_valid_test_split(mydf[0, :])\n",
    "y_train, y_valid, y_test = train_valid_test_split(mydf[1, :])\n",
    "z_train, z_valid, z_test = train_valid_test_split(mydf[2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 50\n",
    "batch_size = 32\n",
    "shuffle_buffer_size = df_train.shape[0]\n",
    "train_dataset = create_df_3d(df_train.transpose(\n",
    "), window_size, batch_size, shuffle_buffer_size)\n",
    "valid_dataset = create_df_3d(df_valid.transpose(), window_size, batch_size, 1)\n",
    "test_dataset = create_df_3d(df_test.transpose(), window_size, batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred, washout=0):\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    # (batchsize, dimensions)\n",
    "    loss = mse(y_true[washout:, :], y_pred[washout:, :])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_open_loop_lstm():\n",
    "    lstm_init = tf.keras.initializers.GlorotUniform(seed=0)\n",
    "    dense_init = tf.keras.initializers.GlorotUniform(seed=1)\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.LSTM(8, activation='tanh',\n",
    "                             name='LSTM_1', kernel_initializer=lstm_init),\n",
    "        tf.keras.layers.Dense(3, name='Dense_1', kernel_initializer=dense_init)\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    mse_loss = tf.keras.losses.MeanSquaredError()\n",
    "    model.compile(loss=custom_loss, optimizer=optimizer, metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_int_window_dist(df_transposed, n_int, window_size=50, batch_size=32):\n",
    "    idx = [batch_size * i for i in sorted(random.sample(range(185), n_int))]\n",
    "    return idx\n",
    "\n",
    "\n",
    "def add_cloop_prediction(df_transposed, idx, predictions):\n",
    "    window_list = np.array(\n",
    "        [\n",
    "            np.append(\n",
    "                df_transposed[idx[i] + 1 : idx[i] + 50, :],\n",
    "                predictions[i, :].reshape(1, 3),\n",
    "                axis=0,\n",
    "            ).reshape(50, 3)\n",
    "            for i in range(0, len(idx))\n",
    "        ]\n",
    "    )\n",
    "    label_list = np.array([df_transposed[i + 52, :] for i in idx])\n",
    "    return window_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_oloop.optimizer.lr.assign(new_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "model_oloop = build_open_loop_lstm()\n",
    "log_dir = \"50_window_100LSTM/Images/LSTM_0_washout/run_1602/logs/fit/\" + \\\n",
    "    datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', patience=10, restore_best_weights=True)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = model_oloop.fit(train_dataset, epochs=100, batch_size=batch_size,\n",
    "                          validation_data=valid_dataset, verbose=1, callbacks=[tensorboard_callback])\n",
    "\n",
    "img_filepath = '50_window_100LSTM/Images/LSTM_10_washout/run_1602/'\n",
    "if not os.path.exists(img_filepath):\n",
    "    os.makedirs(img_filepath)\n",
    "lya_filepath = img_filepath + 'cloop_' + str(history.params['epochs'])+'.png'\n",
    "predictions = plots.plot_closed_loop_lya(\n",
    "    model_oloop, history.params['epochs'], time_test, df_test, n_length=1950)\n",
    "phase_filepath = img_filepath + 'phase_cloop_' + str(history.params['epochs'])+'.png'\n",
    "plots.plot_phase_space(\n",
    "    predictions, history.params['epochs'], df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloop_size = 32*1\n",
    "test_window, labels, idx = select_random_batch_with_label(\n",
    "    df_train.transpose())#, cloop_size)  # np.append(df_train[:, -50:], df_test, axis=1)\n",
    "predictions = model.predict(np.array(test_window).reshape(cloop_size, 50, 3))\n",
    "\n",
    "print(predictions.shape)\n",
    "cloop_windows, cloop_label = add_cloop_prediction(\n",
    "    df_train.transpose(), idx, predictions)\n",
    "print(np.array(cloop_windows).shape, cloop_label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 5):\n",
    "    print('Iteration is ', i)\n",
    "    cloop_size = 32*1\n",
    "    test_window, labels, idx = select_random_batch_with_label(\n",
    "    df_train.transpose())#, cloop_size)  # np.append(df_train[:, -50:], df_test, axis=1)\n",
    "    predictions = model.predict(np.array(test_window).reshape(cloop_size, 50, 3))\n",
    "    cloop_windows, cloop_label = add_cloop_prediction(\n",
    "    df_train.transpose(), idx, predictions)\n",
    "    history = model.fit(cloop_windows, cloop_label, epochs=100, batch_size=32,\n",
    "                        validation_data=valid_dataset, callbacks=[tensorboard_callback, early_stop_callback], verbose=2)\n",
    "\n",
    "    predictions = plots.plot_closed_loop_lya(\n",
    "        model, history.params['epochs'], time_test, df_test, n_length=1950)\n",
    "\n",
    "    plots.plot_phase_space(\n",
    "        predictions, history.params['epochs'], df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_filepath = '100_window_200LSTM/Images/LSTM_10_washout/run_1002/'\n",
    "lya_filepath = img_filepath + 'cloop_' + str(history.params['epochs'])+'.png'\n",
    "predictions = plots.plot_closed_loop_lya(\n",
    "    model, history.params['epochs'], time_test, df_test, n_length=400)\n",
    "phase_filepath = img_filepath + 'phase_cloop_' + \\\n",
    "    str(history.params['epochs'])+'.png'\n",
    "plots.plot_phase_space(\n",
    "    predictions, history.params['epochs'], df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_filepath = '50_window_100LSTM/Images/LSTM_10_washout/run_1002/'\n",
    "\n",
    "if not os.path.exists(img_filepath):\n",
    "    os.makedirs(img_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "model_oloop = build_open_loop_lstm()\n",
    "img_filepath = '100_window_200_LSTM_unnorm/Images/LSTM_10_washout/run_1002/'\n",
    "\n",
    "n_epochs_old = 0\n",
    "# Save the weights\n",
    "for i in range(0, 1):\n",
    "    n_epochs = n_epochs_old + 50\n",
    "    history = model_oloop.fit(train_dataset, epochs=n_epochs, initial_epoch=n_epochs_old, batch_size=batch_size,\n",
    "                              validation_data=valid_dataset, verbose=2)  # , callbacks=[tensorboard_callback]) #, early_stop_callback])\n",
    "    n_epochs_old = n_epochs\n",
    "    lya_filepath = img_filepath + 'cloop_' + str(n_epochs)+'.png'\n",
    "    predictions = plots.plot_closed_loop_lya(\n",
    "        model_oloop, n_epochs, time_test, df_test, lya_filepath, n_length=400)\n",
    "    phase_filepath = img_filepath + 'phase_cloop_' + str(n_epochs)+'.png'\n",
    "    plots.plot_phase_space(predictions, n_epochs, df_test, phase_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.plot_phase_space(predictions, n_epochs, df_test, phase_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = plots.plot_closed_loop_lya(\n",
    "    model_oloop, n_epochs, time_test, df_test, lya_filepath, n_length=1900)\n",
    "phase_filepath = img_filepath + 'phase_cloop_' + str(n_epochs)+'.png'\n",
    "plots.plot_phase_space(predictions, n_epochs, df_test, phase_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_oloop\n",
    "forecast = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = df_test.transpose()[50:, :] - forecast\n",
    "abs_error = np.abs(df_test.transpose()[50:, :] - forecast)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, sharex=True,\n",
    "                                    sharey=True, facecolor='w')  # , figsize=(15, 15))\n",
    "fig.suptitle('Absolute Error on Test Data')\n",
    "ax1.plot(time_test[50:], abs_error[:, 0])\n",
    "ax1.set_ylabel(r'$|x_{true}-x_{pred}|$')\n",
    "ax1.set_yscale('log')\n",
    "ax2.plot(time_test[50:], abs_error[:, 1])\n",
    "ax2.set_ylabel(r'$|y_{true}-y_{pred}|$')\n",
    "ax2.set_yscale('log')\n",
    "ax3.plot(time_test[50:], abs_error[:, 2])\n",
    "ax3.set_ylabel(r'$|z_{true}-z_{pred}|$')\n",
    "ax3.set_xlabel('t')\n",
    "ax3.set_yscale('log')\n",
    "ax3.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "#fig.savefig(error_filepath, dpi=1000, facecolor=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = 'oloop_lstm_Washout_0/250_epoch_cp'\n",
    "# Save the weights\n",
    "model_oloop.save_weights(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_window_with_label(df_transposed, n_windows, window_size=50, n_dim=3):\n",
    "    idx = random.sample(range(len(df_transposed)-window_size-1), n_windows)\n",
    "    window_list = np.array([df_transposed[i:i+window_size, :].reshape(window_size, 3)\n",
    "                           for i in idx])  # .reshape((n_windows,window_size,n_dim))\n",
    "    label_list = np.array([df_transposed[i+window_size+1, :].reshape(n_dim)\n",
    "                          for i in idx])  # .reshape(n_windows, n_dim)\n",
    "    return window_list, label_list, idx\n",
    "\n",
    "\n",
    "def add_cloop_prediction(df_transposed, idx, predictions):\n",
    "    window_list = np.array([np.append(df_train.transpose()[idx[i]+1:idx[i]+50, :],\n",
    "                           predictions[i, :].reshape(1, 3), axis=0).reshape(50, 3) for i in range(0, len(idx))])\n",
    "    label_list = np.array([df_transposed[i+52, :] for i in idx])\n",
    "    return window_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_batch_with_label(df_transposed):\n",
    "    idx_start = random.randint(0, len(df_transposed) - 50 - 1)\n",
    "    idx = np.arange(start=idx_start, stop=idx_start + 32)\n",
    "    # window_list =[]\n",
    "    window_list = [df_transposed[i : i + 50, :].reshape(1, 50, 3) for i in idx]\n",
    "    label_list = [df_transposed[i + 51, :].reshape(1, 3) for i in idx]\n",
    "    return window_list, label_list, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_int_window_dist(df_transposed, n_int, window_size=50, batch_size=32):\n",
    "    \"\"\"returns a list of random ints of length n_int which all have distance n_window\"\"\"\n",
    "    idx = [\n",
    "        (50+batch_size) * i + x\n",
    "        for i, x in enumerate(\n",
    "            sorted(random.sample(range(len(df_transposed) - window_size - batch_size - 1), n_int))\n",
    "        )\n",
    "    ]\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_batches_with_label(df_transposed, n_int, window_size=50, batch_size=32):\n",
    "    idx = random_int_window_dist(df_transposed, n_int, window_size=window_size)\n",
    "    idx_list = np.array([np.arange(start=idx_start, stop=idx_start + 32) for idx_start in idx]).flatten()\n",
    "    window_list = [df_transposed[i : i + 50, :].reshape(1, 50, 3) for i in idx_list]\n",
    "    label_list = [df_transposed[i + 51, :].reshape(1, 3) for i in idx_list]\n",
    "    return np.array(window_list), np.array(label_list), idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_oloop.fit(window_list.reshape(64, 50, 3), label_list, epochs=2, batch_size=32,\n",
    "                        validation_data=valid_dataset, callbacks=[tensorboard_callback, early_stop_callback], verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = model.predict(train_dataset)\n",
    "forecast_err = np.abs(df_train.transpose()[50:, :] - forecast)\n",
    "plt.plot(forecast_err[:, 0])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.abs(labels - predictions)\n",
    "plt.plot(error[:, 1])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[50*i + x for i, x in enumerate(sorted(random.sample(range(1000), 10)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[50*i + x for i, x in enumerate(sorted(random.sample(range(5), 5)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1d65230a6c8a88ce26e29e72a7d5e136a0ce4649ddf60ef59e8160926d3a4bb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
