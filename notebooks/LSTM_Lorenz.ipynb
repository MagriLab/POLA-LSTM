{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3f5813217f5121f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tensorflow_datasets as tfds\n",
    "import random\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from data_processing import create_training_split, df_training_split, train_valid_test_split, df_train_valid_test_split, create_df_3d, create_window_closed_loop, add_new_pred, compute_lyapunov_time_arr\n",
    "from lstm_model import build_open_loop_lstm, load_open_loop_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-57fa3fac0c53b7d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## DATA\n",
    "- Data is generated in Lorenz_data_creation.ipynb\n",
    "- 4D Data (t,x,y,z)\n",
    "- Data is normalized with respect to max(abs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf = np.genfromtxt('CSV/13333_lorenz_normalized.csv', delimiter=',')\n",
    "time = mydf[0, :]\n",
    "mydf = mydf[1:, :]\n",
    "print(\"Shape of discrete time step array \", time.shape)\n",
    "print(\"Shape of solution array: \", mydf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "- training/ testation split 70/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid, df_test = df_train_valid_test_split(mydf)\n",
    "time_train, time_valid, time_test = train_valid_test_split(time)\n",
    "x_train, x_valid, x_test = train_valid_test_split(mydf[0, :])\n",
    "y_train, y_valid, y_test = train_valid_test_split(mydf[1, :])\n",
    "z_train, z_valid, z_test = train_valid_test_split(mydf[2, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-99b72e480168fcd9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Windowing\n",
    "- split the sequential data into windows to be fed into the network in batches\n",
    "- Batch size of 32, Window size of 50, 3D entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transposition needed for windowing of 3D data\n",
    "df_train_transposed = df_train.transpose()\n",
    "df_test_transposed = df_test.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_3d(series, window_size, batch_size, shuffle_buffer):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "    dataset = dataset.window(size=window_size+1, shift=1, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_size+1))\n",
    "    # dataset = dataset.shuffle(7).map(lambda window: (window[:-1], window[-1]))#separates each window into features and label (next/last value)\n",
    "    dataset = dataset.shuffle(shuffle_buffer).map(\n",
    "        lambda window: (window[:-1], window[-1]))\n",
    "    dataset = dataset.padded_batch(batch_size, padded_shapes=([None, 3], [3]))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 50\n",
    "batch_size = 32\n",
    "shuffle_buffer_size = df_train.shape[0]\n",
    "train_dataset = create_df_3d(\n",
    "    df_train_transposed, window_size, batch_size, shuffle_buffer_size)\n",
    "valid_dataset = create_df_3d(df_valid.transpose(), window_size, batch_size, 1)\n",
    "test_dataset = create_df_3d(df_test_transposed, window_size, batch_size, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-581a1cf9bce5522a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## MODEL & TRAINING\n",
    "- build LSTM (same dim as window = 50)\n",
    "- train LSTM (epochs?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list(train_dataset)))\n",
    "for example_inputs, example_labels in train_dataset.take(1):\n",
    "    print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
    "    print(f'Labels shape (batch, time, features): {example_labels.shape}')\n",
    "print(len(list(valid_dataset)))\n",
    "for example_inputs, example_labels in valid_dataset.take(1):\n",
    "    print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
    "    print(f'Labels shape (batch, time, features): {example_labels.shape}')\n",
    "print(len(list(test_dataset)))\n",
    "for example_inputs, example_labels in test_dataset.take(1):\n",
    "    print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
    "    print(f'Labels shape (batch, time, features): {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred, washout=0):\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "    # (batchsize, dimensions)\n",
    "    loss = mse(y_true[washout:, :], y_pred[washout:, :])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_open_loop_lstm():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.LSTM(50, activation='relu', name='LSTM_1'),\n",
    "        tf.keras.layers.Dense(3, name='Dense_1')\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    mse_loss = tf.keras.losses.MeanSquaredError()\n",
    "    model.compile(loss=custom_loss, optimizer=optimizer, metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model_oloop = build_open_loop_lstm()\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', patience=5)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir, histogram_freq=1)\n",
    "history = model_oloop.fit(train_dataset, epochs=100, batch_size=batch_size,\n",
    "                          validation_data=valid_dataset, callbacks=[tensorboard_callback])  # , early_stop_callback])\n",
    "model_oloop.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).to_csv(\n",
    "    \"oloop_lstm_washout3/train_history_100.csv\")\n",
    "hist = pd.read_csv(\"oloop_lstm_washout3/train_history_100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard - -logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = 'models/oloop_lstm/200_epoch_cp'\n",
    "# Save the weights\n",
    "# model_oloop.save_weights(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model instance\n",
    "model = build_open_loop_lstm()\n",
    "\n",
    "# Restore the weights\n",
    "model.load_weights(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c4247c1ac572cac8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## EVALUATE\n",
    "Use the LSTM model to predict and plot the testation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_oloop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_window_closed_loop(test_data, iteration, pred=np.array([])):\n",
    "    if iteration == 0:\n",
    "        print(\"no network prediction yet\")\n",
    "        return test_data[:50, :].reshape(1, 50, 3)\n",
    "    if iteration < 50:\n",
    "        n_pred = pred.shape[0]\n",
    "        # end index of entries from the test data,\n",
    "        idx_test_entries = iteration + 50 - n_pred\n",
    "        test_data = test_data[iteration: idx_test_entries, :]\n",
    "        return np.append(test_data, pred, axis=0).reshape(1, 50, 3)\n",
    "    else:\n",
    "        return pred[-50:, :].reshape(1, 50, 3)\n",
    "\n",
    "\n",
    "def add_new_pred(pred_old, pred_new):\n",
    "    return np.append(pred_old, pred_new, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closed_loop_loss(true_val, pred_val):\n",
    "    return tf.keras.metrics.mean_squared_error(true_val, pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_window_with_label(df_transposed, n_windows):\n",
    "    idx = random.sample(range(len(df_transposed)-50-1), n_windows)\n",
    "    #window_list =[]\n",
    "    window_list = [df_transposed[i:i+50, :].reshape(1, 50, 3) for i in idx]\n",
    "    label_list = [df_transposed[i+51, :].reshape(1, 3) for i in idx]\n",
    "    return window_list, label_list, idx\n",
    "\n",
    "\n",
    "def add_cloop_prediction(df_transposed, idx, predictions):\n",
    "    window_list = np.array([np.append(df_train.transpose()[idx[i]+1:idx[i]+50, :],\n",
    "                           predictions[i, :].reshape(1, 3), axis=0).reshape(50, 3) for i in range(0, len(idx))])\n",
    "    label_list = np.array([df_transposed[i+52, :] for i in idx])\n",
    "    return window_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.append(df_train[:, -50:], df_test, axis=1)\n",
    "test_window = create_window_closed_loop(df_test.transpose(), 0)\n",
    "predictions = model.predict(test_window)\n",
    "for iteration in range(1, 1000):\n",
    "    test_window = create_window_closed_loop(\n",
    "        df_test.transpose(), iteration, predictions)\n",
    "    new_pred = model.predict(test_window)\n",
    "    predictions = add_new_pred(predictions, new_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_closed_loop = predictions\n",
    "test_time_end = len(predictions)\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, sharex=True,\n",
    "                                    sharey=True, facecolor=\"white\")  # , figsize=(15, 15))\n",
    "fig.suptitle('Closed Loop LSTM Prediction')\n",
    "ax1.plot(lyapunov_time[:test_time_end],\n",
    "         x_test[50:50+test_time_end], label='True Data')\n",
    "ax1.plot(lyapunov_time[:test_time_end],\n",
    "         pred_closed_loop[:, 0], '--', label='RNN Prediction')\n",
    "ax1.set_ylabel('x')\n",
    "\n",
    "ax2.plot(lyapunov_time[:test_time_end],\n",
    "         y_test[50:50+test_time_end], label='data')\n",
    "ax2.plot(lyapunov_time[:test_time_end], pred_closed_loop[:,\n",
    "         1], '--', label='RNN prediction on test data')\n",
    "ax2.set_ylabel('y')\n",
    "ax3.plot(lyapunov_time[:test_time_end],\n",
    "         z_test[50:50+test_time_end], label='True Data')\n",
    "ax3.plot(lyapunov_time[:test_time_end],\n",
    "         pred_closed_loop[:, 2], '--', label='LSTM prediction')\n",
    "ax3.set_ylabel('z')\n",
    "ax3.set_xlabel('Lyapunov time')\n",
    "ax3.set_ylim(-1, 1)\n",
    "# ax3.set_xlim(0,5)\n",
    "ax3.legend(loc='center left', bbox_to_anchor=(1, 2.0))\n",
    "plt.show()\n",
    "#fig.savefig(lyapunov_path, dpi=1000, facecolor=\"w\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.append(df_train[:, -50:], df_test, axis=1)\n",
    "test_window = create_window_closed_loop(df_test.transpose(), 0)\n",
    "predictions = model.predict(test_window)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_window_bathjes_with_label(df_transposed, n_batches=5, cloop_step=1, batch_size=32):\n",
    "    idx = random.sample(range(len(df_transposed)-50-1), n_batches*batch_size)\n",
    "    #window_list =[]\n",
    "    window_list = [df_transposed[i:i+50, :].reshape(1, 50, 3) for i in idx]\n",
    "    label_list = [df_transposed[i+51, :].reshape(1, 3) for i in idx]\n",
    "    return window_list, label_list, idx\n",
    "\n",
    "\n",
    "def add_cloop_prediction(df_transposed, idx, predictions):\n",
    "    window_list = np.array([np.append(df_train.transpose()[idx[i]+1:idx[i]+50, :],\n",
    "                           predictions[i, :].reshape(1, 3), axis=0).reshape(50, 3) for i in range(0, len(idx))])\n",
    "    label_list = np.array([df_transposed[i+52, :] for i in idx])\n",
    "    return window_list, label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloop_size = 32*10\n",
    "test_window, labels, idx = select_random_window_with_label(\n",
    "    df_train.transpose(), cloop_size)  # np.append(df_train[:, -50:], df_test, axis=1)\n",
    "predictions = model.predict(np.array(test_window).reshape(cloop_size, 50, 3))\n",
    "\n",
    "print(predictions.shape)\n",
    "cloop_windows, cloop_label = add_cloop_prediction(\n",
    "    df_train.transpose(), idx, predictions)\n",
    "print(np.array(cloop_windows).shape, cloop_label.shape)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "model.compile(loss='mse', optimizer='adam', metric='mse')\n",
    "model.fit(cloop_windows, cloop_label, epochs=100, batch_size=32,\n",
    "          validation_data=valid_dataset, callbacks=[tensorboard_callback])  # , early_stop_callback])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows, label = add_cloop_prediction(df_train.transpose(), idx, predictions)\n",
    "#window_list = [np.append(df_train.transpose()[idx[i]+1:idx[i]+50, :], predictions[i, :].reshape(1,3), axis=0).reshape(1, 50, 3) for i in range(0,len(idx))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_oloop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.append(df_train[:, -50:], df_test, axis=1)\n",
    "test_window = create_window_closed_loop(df_test.transpose(), 0)\n",
    "predictions = model.predict(test_window)\n",
    "for iteration in range(1, 2000):\n",
    "    test_window = create_window_closed_loop(\n",
    "        df_test.transpose(), iteration, predictions)\n",
    "    new_pred = model.predict(test_window)\n",
    "    predictions = add_new_pred(predictions, new_pred)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(df_test[:, 50]-forecast[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = model.predict(test_dataset)\n",
    "forecast[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyapunov_time = compute_lyapunov_time_arr(time_test)\n",
    "print(lyapunov_time.shape)\n",
    "pred_closed_loop = predictions\n",
    "test_time_end = len(predictions)\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, sharex=True,\n",
    "                                    sharey=True, facecolor=\"white\")  # , figsize=(15, 15))\n",
    "fig.suptitle('Closed Loop LSTM Prediction')\n",
    "ax1.plot(lyapunov_time[:test_time_end],\n",
    "         x_test[50:50+test_time_end], label='True Data')\n",
    "ax1.plot(lyapunov_time[:test_time_end],\n",
    "         pred_closed_loop[:, 0], '--', label='RNN Prediction')\n",
    "ax1.set_ylabel('x')\n",
    "\n",
    "ax2.plot(lyapunov_time[:test_time_end],\n",
    "         y_test[50:50+test_time_end], label='data')\n",
    "ax2.plot(lyapunov_time[:test_time_end], pred_closed_loop[:,\n",
    "         1], '--', label='RNN prediction on test data')\n",
    "ax2.set_ylabel('y')\n",
    "ax3.plot(lyapunov_time[:test_time_end],\n",
    "         z_test[50:50+test_time_end], label='True Data')\n",
    "ax3.plot(lyapunov_time[:test_time_end],\n",
    "         pred_closed_loop[:, 2], '--', label='LSTM prediction')\n",
    "ax3.set_ylabel('z')\n",
    "ax3.set_xlabel('Lyapunov time')\n",
    "ax3.set_ylim(-1, 1)\n",
    "# ax3.set_xlim(0,5)\n",
    "ax3.legend(loc='center left', bbox_to_anchor=(1, 2.0))\n",
    "plt.show()\n",
    "#fig.savefig(lyapunov_path, dpi=1000, facecolor=\"w\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model_oloop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = model.predict(test_dataset)\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, sharex=True,\n",
    "                                    sharey=True, facecolor=\"white\")  # , figsize=(15, 15))\n",
    "fig.suptitle('LSTM Prediction on testation Data')\n",
    "ax1.plot(time_test[50:], x_test[50:], label='data')\n",
    "ax1.plot(time_test[50:], forecast[:, 0], '--',\n",
    "         label='RNN prediction on test data')\n",
    "ax1.set_ylabel('x')\n",
    "ax2.plot(time_test[50:], y_test[50:], label='data')\n",
    "ax2.plot(time_test[50:], forecast[:, 1], '--',\n",
    "         label='RNN prediction on test data')\n",
    "ax2.set_ylabel('y')\n",
    "ax3.plot(time_test[50:], z_test[50:], label='data')\n",
    "ax3.plot(time_test[50:], forecast[:, 2], '--',\n",
    "         label='LSTM prediction on test data')\n",
    "ax3.set_ylabel('z')\n",
    "ax3.set_xlabel('t')\n",
    "ax3.set_ylim(-1, 1)\n",
    "ax3.legend(loc='center left', bbox_to_anchor=(1, 2.0))\n",
    "#fig.savefig(testation_filepath, dpi=1000, facecolor=\"w\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = df_test.transpose()[50:, :] - forecast\n",
    "abs_error = np.abs(df_test.transpose()[50:, :] - forecast)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, sharex=True,\n",
    "                                    sharey=True, facecolor='w')  # , figsize=(15, 15))\n",
    "fig.suptitle('Absolute Error on Test Data')\n",
    "ax1.plot(time_test[50:], abs_error[:, 0])\n",
    "ax1.set_ylabel(r'$|x_{true}-x_{pred}|$')\n",
    "ax1.set_yscale('log')\n",
    "ax2.plot(time_test[50:], abs_error[:, 1])\n",
    "ax2.set_ylabel(r'$|y_{true}-y_{pred}|$')\n",
    "ax2.set_yscale('log')\n",
    "ax3.plot(time_test[50:], abs_error[:, 2])\n",
    "ax3.set_ylabel(r'$|z_{true}-z_{pred}|$')\n",
    "ax3.set_xlabel('t')\n",
    "ax3.set_yscale('log')\n",
    "ax3.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "#fig.savefig(error_filepath, dpi=1000, facecolor=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = model.predict(valid_dataset)\n",
    "err = df_valid.transpose()[50:, :] - forecast\n",
    "abs_error = np.abs(df_valid.transpose()[50:, :] - forecast)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, sharex=True,\n",
    "                                    sharey=True, facecolor='w')  # , figsize=(15, 15))\n",
    "fig.suptitle('Absolute Error on Test Data')\n",
    "ax1.plot(time_test[50:], abs_error[:, 0])\n",
    "ax1.set_ylabel(r'$|x_{true}-x_{pred}|$')\n",
    "ax1.set_yscale('log')\n",
    "ax2.plot(time_test[50:], abs_error[:, 1])\n",
    "ax2.set_ylabel(r'$|y_{true}-y_{pred}|$')\n",
    "ax2.set_yscale('log')\n",
    "ax3.plot(time_test[50:], abs_error[:, 2])\n",
    "ax3.set_ylabel(r'$|z_{true}-z_{pred}|$')\n",
    "ax3.set_xlabel('t')\n",
    "ax3.set_yscale('log')\n",
    "ax3.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "#fig.savefig(error_filepath, dpi=1000, facecolor=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "interpreter": {
   "hash": "495eb407548ead797f34be8f3666f32c9abb47a79f45c8774fe78570ada3c2e8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
