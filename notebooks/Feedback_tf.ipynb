{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm_model import build_open_loop_lstm, load_open_loop_lstm\n",
    "from data_processing import create_training_split, df_training_split, train_valid_test_split, df_train_valid_test_split, create_df_3d, create_window_closed_loop, add_new_pred, compute_lyapunov_time_arr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime, time\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import lstm_model\n",
    "import importlib\n",
    "import Feedback_Model\n",
    "import data_processing\n",
    "import plots\n",
    "plt.rcParams[\"figure.facecolor\"] = \"w\"\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "importlib.reload(Feedback_Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf = np.genfromtxt('CSV/Lorenz_trans_001.csv', delimiter=',')\n",
    "time = mydf[0, :]\n",
    "mydf = mydf[1:, :]\n",
    "print(\"Shape of discrete time step array \", time.shape)\n",
    "print(\"Shape of solution array: \", mydf.shape)\n",
    "df_train, df_valid, df_test = df_train_valid_test_split(mydf)\n",
    "time_train, time_valid, time_test = train_valid_test_split(time)\n",
    "x_train, x_valid, x_test = train_valid_test_split(mydf[0, :])\n",
    "y_train, y_valid, y_test = train_valid_test_split(mydf[1, :])\n",
    "z_train, z_valid, z_test = train_valid_test_split(mydf[2, :])\n",
    "window_size = 50\n",
    "batch_size = 32\n",
    "shuffle_buffer_size = df_train.shape[0]\n",
    "train_dataset = create_df_3d(df_train.transpose(), window_size, batch_size, shuffle_buffer_size)\n",
    "valid_dataset = create_df_3d(df_valid.transpose(), window_size, batch_size, 1)\n",
    "test_dataset = create_df_3d(df_test.transpose(), window_size, batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only take first element of dataset\n",
    "for data, labels in train_dataset.take(1):\n",
    "    numpy_data = data.numpy()\n",
    "    numpy_labels = labels.numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', patience=5)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir, histogram_freq=1)\n",
    "history = model_oloop.fit(train_dataset, epochs=100, batch_size=batch_size,\n",
    "                          validation_data=valid_dataset, callbacks=[tensorboard_callback])  # , early_stop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred, washout=0):\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    # (batchsize, dimensions)\n",
    "    loss = mse(y_true[washout:, :], y_pred[washout:, :])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_model = Feedback_Model.FeedBack(units=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_model.fit(train_dataset, epochs=10, batch_size=32,\n",
    "                   validation_data=valid_dataset, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = plots.plot_closed_loop_lya(\n",
    "    feedback_model,\n",
    "    2,\n",
    "    time_test,\n",
    "    df_test,\n",
    "    img_filepath=None,\n",
    "    n_length=500,\n",
    "    window_size=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 0 + 100\n",
    "n_batches = 180\n",
    "cloop_size = 32 * n_batches\n",
    "test_window, labels, idx = lstm_model.select_random_batches_with_label(\n",
    "    df_train.transpose(), n_batches\n",
    ")\n",
    "predictions = feedback_model.predict(np.array(test_window).reshape(cloop_size, 50, 3))\n",
    "cloop_windows, cloop_label = lstm_model.add_cloop_prediction(\n",
    "    df_train.transpose(), idx, np.array(predictions).reshape((cloop_size, 1, 3))\n",
    ")\n",
    "cloop_dataset = tf.data.Dataset.from_tensor_slices((cloop_windows, cloop_label.reshape(cloop_size,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloop_dataset = cloop_dataset.padded_batch(32, padded_shapes=([None, 3], [None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_model.train_cloop(train_dataset, cloop_dataset, 5, 2, valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = plots.plot_closed_loop_lya(\n",
    "    feedback_model,\n",
    "    50,\n",
    "    time_test,\n",
    "    df_test,\n",
    "    img_filepath=None,\n",
    "    n_length=500,\n",
    "    window_size=50,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12dfb561970cfd3a0c79700abcce3f060c3d9f3c45d80594c54d868f07b2d125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
